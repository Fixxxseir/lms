import streamlit as st
import PyPDF2
import io
import base64
import requests
from opensearchpy import OpenSearch, helpers

st.set_page_config(page_title="PDF Search App", layout="wide")

# Connect to OpenSearch
osrch = OpenSearch(hosts=["http://localhost:9200"], timeout=3600)
opensearch_url = "http://localhost:9200"

# Initialization
PDF_INDEX = "pdf_files"
CHUNKS_INDEX = "chunks"

def unlock_opensearch_cluster():
    url = f"{opensearch_url}/_cluster/settings"
    headers = {"Content-Type": "application/json"}
    data = {
        "persistent": {
            "cluster.blocks.read_only": False,
            "cluster.blocks.read_only_allow_delete": False
        }
    }
    try:
        requests.put(url, json=data, headers=headers)
    except requests.RequestException as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∫–µ OpenSearch: {e}")

def create_opensearch_index():
    try:
        if not osrch.indices.exists(index=CHUNKS_INDEX):
            osrch.indices.create(
                index=CHUNKS_INDEX,
                body={
                    "settings": {
                        "analysis": {
                            "analyzer": {"default": {"type": "russian"}}
                        }
                    }
                },
            )
        if not osrch.indices.exists(index=PDF_INDEX):
            osrch.indices.create(index=PDF_INDEX)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–Ω–¥–µ–∫—Å–æ–≤: {e}")

def index_pdf(file_bytes: bytes, filename: str):
    try:
        encoded_data = base64.b64encode(file_bytes).decode('utf-8')
        osrch.index(index=PDF_INDEX, body={"filename": filename, "file_data": encoded_data})
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ PDF: {e}")

def index_chunks(chunks, source):
    actions = (
        {
            "_op_type": "index",
            "_index": CHUNKS_INDEX,
            "_source": {
                "chunk_number": i + 1,
                "source": source,
                "content": chunk,
                "page": page
            }
        }
        for i, (page, chunk) in enumerate(chunks)
    )
    try:
        helpers.bulk(osrch, actions, refresh=True)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —á–∞–Ω–∫–æ–≤: {e}")

def load_pdf(file_bytes: bytes):
    try:
        reader = PyPDF2.PdfReader(io.BytesIO(file_bytes))
        result = []
        for i, page in enumerate(reader.pages):
            text = page.extract_text() or ""
            for paragraph in text.split("\n\n"):
                cleaned = paragraph.strip()
                if cleaned:
                    result.append((i + 1, cleaned))
        return result
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–±–æ—Ä–µ PDF: {e}")
        return []

def search_opensearch(keyword):
    try:
        response = osrch.search(
            index=CHUNKS_INDEX,
            body={
                "query": {
                    "match": {
                        "content": {
                            "query": keyword,
                            "operator": "and",
                            "fuzziness": "1"
                        }
                    }
                }
            },
            size=10000,
        )
        return [
            {
                "content": hit["_source"]["content"],
                "source": hit["_source"]["source"],
                "page": hit["_source"].get("page"),
                "link": f"/pdf/{hit['_source']['source']}#page={hit['_source'].get('page', 1)}"
            }
            for hit in response["hits"]["hits"]
        ]
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}")
        return []

def retrieve_pdf_bytes(filename: str):
    try:
        response = osrch.search(
            index=PDF_INDEX,
            body={"query": {"match": {"filename": filename}}},
            size=1
        )
        hits = response["hits"]["hits"]
        if not hits:
            return None
        encoded = hits[0]['_source']['file_data']
        return base64.b64decode(encoded)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ PDF: {e}")
        return None

# UI
st.title("üìÑ PDF –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –ü–æ–∏—Å–∫ –ø–æ OpenSearch")
unlock_opensearch_cluster()
create_opensearch_index()

menu = st.sidebar.radio("–ù–∞–≤–∏–≥–∞—Ü–∏—è", ["–ó–∞–≥—Ä—É–∑–∏—Ç—å PDF", "–ü–æ–∏—Å–∫"])

if menu == "–ó–∞–≥—Ä—É–∑–∏—Ç—å PDF":
    uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ PDF", type=["pdf"])
    if uploaded_file is not None:
        file_bytes = uploaded_file.read()
        chunks = load_pdf(file_bytes)
        if chunks:
            index_pdf(file_bytes, uploaded_file.name)
            index_chunks(chunks, uploaded_file.name)
            st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {len(chunks)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")

elif menu == "–ü–æ–∏—Å–∫":
    keyword = st.text_input("üîç –í–≤–µ–¥–∏—Ç–µ —Å–ª–æ–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ PDF")
    if keyword:
        results = search_opensearch(keyword)
        if results:
            for i, res in enumerate(results):
                st.markdown(f"**–§–∞–π–ª:** `{res['source']}` | –°—Ç—Ä–∞–Ω–∏—Ü–∞: {res['page']}")
                st.write(res['content'])
                if st.button(f"–°–∫–∞—á–∞—Ç—å {res['source']}", key=f"btn_{res['source']}_{res['page']}_{i}"):
                    pdf_data = retrieve_pdf_bytes(res['source'])
                    if pdf_data:
                        st.download_button(
                            label="üì• –°–∫–∞—á–∞—Ç—å PDF",
                            data=pdf_data,
                            file_name=res['source'],
                            mime="application/pdf",
                            key=f"download_{res['source']}_{i}"
                        )
        else:
            st.info("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ –¥–∞–Ω–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É.")
